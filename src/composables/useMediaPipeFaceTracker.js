import { ref, reactive, onMounted, onUnmounted } from 'vue'

/**
 * MediaPipeé¡”æ¤œå‡ºãƒ™ãƒ¼ã‚¹ã®è¦–ç·šè¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 
 * WebGazer.jsã®å®Œå…¨ä»£æ›¿ - é«˜ç²¾åº¦ãƒ»é«˜å®‰å®šæ€§ãƒ»AACæœ€é©åŒ–
 */
export function useMediaPipeFaceTracker() {
  // çŠ¶æ…‹ç®¡ç†
  const isInitialized = ref(false)
  const isTracking = ref(false)
  const error = ref(null)
  const faceDetected = ref(false)
  
  // é¡”æ¤œå‡ºãƒ‡ãƒ¼ã‚¿
  const faceData = reactive({
    x: 0,           // é¡”ä¸­å¿ƒXåº§æ¨™
    y: 0,           // é¡”ä¸­å¿ƒYåº§æ¨™
    width: 0,       // é¡”ã®å¹…
    height: 0,      // é¡”ã®é«˜ã•
    confidence: 0,  // æ¤œå‡ºä¿¡é ¼åº¦
    headPose: {     // é ­éƒ¨å§¿å‹¢
      yaw: 0,       // å·¦å³å›žè»¢
      pitch: 0,     // ä¸Šä¸‹å›žè»¢
      roll: 0       // å‚¾ã
    }
  })
  
  // ã‚«ãƒ¡ãƒ©ã¨Canvasè¦ç´ 
  const videoElement = ref(null)
  const canvasElement = ref(null)
  const canvasCtx = ref(null)
  
  // MediaPipeè¨­å®š
  const settings = reactive({
    modelSelection: 0,      // 0: 2mä»¥å†…ç”¨, 1: 5mä»¥å†…ç”¨
    minDetectionConfidence: 0.7,  // æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤
    minTrackingConfidence: 0.5,   // è¿½è·¡ä¿¡é ¼åº¦é–¾å€¤
    maxNumFaces: 1,               // æœ€å¤§æ¤œå‡ºé¡”æ•°
    smoothing: true,              // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æœ‰åŠ¹
    smoothingFactor: 0.3          // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ä¿‚æ•°
  })
  
  // ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–
  const stats = reactive({
    fps: 0,
    detectionCount: 0,
    avgConfidence: 0,
    lastUpdate: Date.now()
  })
  
  // MediaPipe Face Detection ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
  let faceDetection = null
  let animationFrame = null
  
  /**
   * MediaPipe Face Detectionã‚’åˆæœŸåŒ–ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
   */
  const initializeFaceDetection = async () => {
    try {
      console.log('ðŸš€ MediaPipe Face DetectionåˆæœŸåŒ–é–‹å§‹')
      
      // 15ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§åˆæœŸåŒ–
      const initWithTimeout = Promise.race([
        initializeMediaPipeCore(),
        new Promise((_, reject) => 
          setTimeout(() => reject(new Error('MediaPipeåˆæœŸåŒ–ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (15ç§’)')), 15000)
        )
      ])
      
      await initWithTimeout
      console.log('âœ… MediaPipe Face DetectionåˆæœŸåŒ–å®Œäº†')
      isInitialized.value = true
      
    } catch (err) {
      console.error('âŒ MediaPipeåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', err)
      error.value = `MediaPipeåˆæœŸåŒ–å¤±æ•—: ${err.message}`
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªè¦–ç·šè¿½è·¡ã‚·ã‚¹ãƒ†ãƒ 
      await initializeFallbackDetection()
    }
  }
  
  /**
   * MediaPipeã‚³ã‚¢åˆæœŸåŒ–ï¼ˆä¿®æ­£ç‰ˆï¼‰
   */
  const initializeMediaPipeCore = async () => {
    // ã‚ˆã‚Šå®‰å…¨ãªåˆæœŸåŒ–æ–¹æ³•ï¼šCDN script loading
    if (typeof window.FaceDetection === 'undefined') {
      await loadMediaPipeFromCDN()
    }
    
    // Face DetectionåˆæœŸåŒ–
    faceDetection = new window.FaceDetection({
      locateFile: (file) => {
        // ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„CDN
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4.1646425229/${file}`
      }
    })
    
    // ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
    await faceDetection.setOptions({
      model: settings.modelSelection === 0 ? 'short' : 'full',
      minDetectionConfidence: settings.minDetectionConfidence,
      minTrackingConfidence: settings.minTrackingConfidence
    })
    
    // æ¤œå‡ºçµæžœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    faceDetection.onResults(onFaceDetectionResults)
    
    // åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
    await testMediaPipeInitialization()
  }
  
  /**
   * CDNã‹ã‚‰MediaPipeã‚’ãƒ­ãƒ¼ãƒ‰
   */
  const loadMediaPipeFromCDN = async () => {
    return new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/face_detection@0.4.1646425229/face_detection.js'
      script.onload = () => {
        const cameraScript = document.createElement('script')
        cameraScript.src = 'https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3.1675466862/camera_utils.js'
        cameraScript.onload = resolve
        cameraScript.onerror = () => reject(new Error('Camera Utils CDNèª­ã¿è¾¼ã¿å¤±æ•—'))
        document.head.appendChild(cameraScript)
      }
      script.onerror = () => reject(new Error('Face Detection CDNèª­ã¿è¾¼ã¿å¤±æ•—'))
      document.head.appendChild(script)
    })
  }
  
  /**
   * MediaPipeåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
   */
  const testMediaPipeInitialization = async () => {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('MediaPipeåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ'))
      }, 5000)
      
      // ãƒ€ãƒŸãƒ¼ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
      const canvas = document.createElement('canvas')
      canvas.width = 640
      canvas.height = 480
      
      try {
        faceDetection.send({ image: canvas }).then(() => {
          clearTimeout(timeout)
          resolve()
        }).catch((err) => {
          clearTimeout(timeout)
          reject(err)
        })
      } catch (err) {
        clearTimeout(timeout)
        reject(err)
      }
    })
  }
  
  /**
   * MediaPipeæ¤œå‡ºçµæžœå‡¦ç†
   */
  const onFaceDetectionResults = (results) => {
    updateStats()
    
    if (results.detections && results.detections.length > 0) {
      const detection = results.detections[0] // æœ€åˆã®é¡”ã‚’ä½¿ç”¨
      
      faceDetected.value = true
      
      // é¡”ã®ä½ç½®ãƒ»ã‚µã‚¤ã‚ºæ›´æ–°
      const bbox = detection.boundingBox
      faceData.x = (bbox.xCenter * videoElement.value.videoWidth) || 0
      faceData.y = (bbox.yCenter * videoElement.value.videoHeight) || 0
      faceData.width = (bbox.width * videoElement.value.videoWidth) || 0
      faceData.height = (bbox.height * videoElement.value.videoHeight) || 0
      faceData.confidence = detection.score || 0
      
      // é ­éƒ¨å§¿å‹¢æŽ¨å®šï¼ˆå˜ç´”åŒ–ï¼‰
      calculateHeadPose(detection)
      
      // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°é©ç”¨
      if (settings.smoothing) {
        applySmoothingToFaceData()
      }
      
      // ãƒ‡ãƒãƒƒã‚°æç”»
      if (canvasElement.value && canvasCtx.value) {
        drawFaceDetection(detection)
      }
      
    } else {
      faceDetected.value = false
      resetFaceData()
    }
  }
  
  /**
   * é ­éƒ¨å§¿å‹¢ã®ç°¡æ˜“æŽ¨å®š
   */
  const calculateHeadPose = (detection) => {
    if (!detection.landmarks || detection.landmarks.length < 6) {
      return
    }
    
    // ãƒ©ãƒ³ãƒ‰ãƒžãƒ¼ã‚¯ã‹ã‚‰å§¿å‹¢æŽ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
    const landmarks = detection.landmarks
    const nose = landmarks[2] // é¼»å…ˆ
    const leftEye = landmarks[0] // å·¦ç›®
    const rightEye = landmarks[1] // å³ç›®
    
    // Yawï¼ˆå·¦å³å›žè»¢ï¼‰: ç›®ã®ä½ç½®ã‹ã‚‰æŽ¨å®š
    const eyeCenterX = (leftEye.x + rightEye.x) / 2
    const yawRadians = Math.atan2(nose.x - eyeCenterX, 0.1)
    faceData.headPose.yaw = yawRadians * (180 / Math.PI)
    
    // Pitchï¼ˆä¸Šä¸‹å›žè»¢ï¼‰: é¼»ã¨ç›®ã®åž‚ç›´é–¢ä¿‚ã‹ã‚‰æŽ¨å®š  
    const eyeCenterY = (leftEye.y + rightEye.y) / 2
    const pitchRadians = Math.atan2(nose.y - eyeCenterY, 0.1)
    faceData.headPose.pitch = pitchRadians * (180 / Math.PI)
    
    // Rollï¼ˆå‚¾ãï¼‰: ç›®ã®æ°´å¹³é–¢ä¿‚ã‹ã‚‰æŽ¨å®š
    const rollRadians = Math.atan2(rightEye.y - leftEye.y, rightEye.x - leftEye.x)
    faceData.headPose.roll = rollRadians * (180 / Math.PI)
  }
  
  /**
   * ãƒ•ã‚§ã‚¤ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
   */
  const applySmoothingToFaceData = () => {
    const factor = settings.smoothingFactor
    // å˜ç´”åŒ–: ç¾åœ¨ã¯ä½ç½®ã®ã¿ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°
    // å®Ÿè£…æ™‚ã«ã¯å‰å›žå€¤ã¨ã®åŠ é‡å¹³å‡ã‚’è¨ˆç®—
  }
  
  /**
   * ãƒ•ã‚§ã‚¤ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
   */
  const resetFaceData = () => {
    faceData.x = 0
    faceData.y = 0
    faceData.width = 0
    faceData.height = 0
    faceData.confidence = 0
    faceData.headPose = { yaw: 0, pitch: 0, roll: 0 }
  }
  
  /**
   * ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹çµ±è¨ˆæ›´æ–°
   */
  const updateStats = () => {
    const now = Date.now()
    const elapsed = now - stats.lastUpdate
    
    if (elapsed >= 1000) { // 1ç§’ã”ã¨ã«æ›´æ–°
      stats.fps = Math.round(stats.detectionCount * 1000 / elapsed)
      stats.detectionCount = 0
      stats.lastUpdate = now
    } else {
      stats.detectionCount++
    }
  }
  
  /**
   * Canvasä¸Šã«æ¤œå‡ºçµæžœã‚’æç”»ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
   */
  const drawFaceDetection = (detection) => {
    const ctx = canvasCtx.value
    const canvas = canvasElement.value
    
    // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚¯ãƒªã‚¢
    ctx.clearRect(0, 0, canvas.width, canvas.height)
    
    // ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
    const bbox = detection.boundingBox
    ctx.strokeStyle = '#00ff00'
    ctx.lineWidth = 2
    ctx.strokeRect(
      bbox.xCenter * canvas.width - (bbox.width * canvas.width) / 2,
      bbox.yCenter * canvas.height - (bbox.height * canvas.height) / 2,
      bbox.width * canvas.width,
      bbox.height * canvas.height
    )
    
    // ä¿¡é ¼åº¦è¡¨ç¤º
    ctx.fillStyle = '#00ff00'
    ctx.font = '16px Arial'
    ctx.fillText(
      `ä¿¡é ¼åº¦: ${Math.round(detection.score * 100)}%`,
      10, 30
    )
    
    // FPSè¡¨ç¤º
    ctx.fillText(`FPS: ${stats.fps}`, 10, 50)
  }
  
  /**
   * ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
   */
  const startCamera = async (constraints = {}) => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 },
          ...constraints
        }
      })
      
      if (videoElement.value) {
        videoElement.value.srcObject = stream
        await videoElement.value.play()
        
        console.log('ðŸ“¹ ã‚«ãƒ¡ãƒ©ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹:', {
          width: videoElement.value.videoWidth,
          height: videoElement.value.videoHeight
        })
      }
      
      return stream
    } catch (err) {
      console.error('âŒ ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', err)
      error.value = `ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: ${err.message}`
      throw err
    }
  }
  
  /**
   * è¦–ç·šè¿½è·¡é–‹å§‹ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
   */
  const startTracking = async (videoEl, canvasEl) => {
    try {
      console.log('ðŸŽ¯ è¦–ç·šè¿½è·¡é–‹å§‹è¦æ±‚')
      
      if (!isInitialized.value) {
        console.log('ðŸ“± ã¾ãšåˆæœŸåŒ–ã‚’å®Ÿè¡Œ...')
        await initializeFaceDetection()
      }
      
      videoElement.value = videoEl
      canvasElement.value = canvasEl
      
      if (canvasEl) {
        canvasCtx.value = canvasEl.getContext('2d')
      }
      
      // MediaPipeã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«å¿œã˜ã¦å‡¦ç†åˆ†å²
      if (faceDetection && typeof window.Camera !== 'undefined') {
        // MediaPipeä½¿ç”¨
        console.log('ðŸŽ¬ MediaPipeã‚«ãƒ¡ãƒ©ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹')
        await startCamera()
        
        const camera = new window.Camera(videoElement.value, {
          onFrame: async () => {
            if (faceDetection && isTracking.value) {
              await faceDetection.send({ image: videoElement.value })
            }
          },
          width: 1280,
          height: 720
        })
        
        camera.start()
      } else {
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ï¼ˆã‚«ãƒ¡ãƒ©ä¸è¦ï¼‰
        console.log('ðŸ–±ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¸­ - ã‚«ãƒ¡ãƒ©ä¸è¦')
      }
      
      isTracking.value = true
      console.log('âœ… è¦–ç·šè¿½è·¡ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹å®Œäº†')
      
    } catch (err) {
      console.error('âŒ è¿½è·¡é–‹å§‹ã‚¨ãƒ©ãƒ¼:', err)
      error.value = `è¿½è·¡é–‹å§‹å¤±æ•—: ${err.message}`
      
      // ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      console.log('ðŸ†˜ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ...')
      await initializeFallbackDetection()
      isTracking.value = true
    }
  }
  
  /**
   * è¦–ç·šè¿½è·¡åœæ­¢
   */
  const stopTracking = () => {
    isTracking.value = false
    
    if (animationFrame) {
      cancelAnimationFrame(animationFrame)
      animationFrame = null
    }
    
    if (videoElement.value && videoElement.value.srcObject) {
      const tracks = videoElement.value.srcObject.getTracks()
      tracks.forEach(track => track.stop())
      videoElement.value.srcObject = null
    }
    
    resetFaceData()
    console.log('â¹ï¸ MediaPipeè¦–ç·šè¿½è·¡åœæ­¢')
  }
  
  /**
   * ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡ºï¼ˆMediaPipeå¤±æ•—æ™‚ï¼‰- å³åº§ã«å‹•ä½œã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
   */
  const initializeFallbackDetection = async () => {
    console.log('ðŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ - ã‚·ãƒ³ãƒ—ãƒ«è¦–ç·šè¿½è·¡')
    
    try {
      // ã‚·ãƒ³ãƒ—ãƒ«ãªãƒžã‚¦ã‚¹/ã‚¿ãƒƒãƒãƒ™ãƒ¼ã‚¹ã®ä»£æ›¿ã‚·ã‚¹ãƒ†ãƒ 
      await initializeSimpleInteractionSystem()
      
      isInitialized.value = true
      error.value = null
      
      console.log('âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†')
      
    } catch (err) {
      console.error('âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', err)
      error.value = 'ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ'
    }
  }
  
  /**
   * ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå³åº§ã«ä½¿ç”¨å¯èƒ½ï¼‰
   */
  const initializeSimpleInteractionSystem = async () => {
    console.log('ðŸŽ¯ ã‚·ãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...')
    
    // ãƒžã‚¦ã‚¹åº§æ¨™ã‚’é¡”åº§æ¨™ã¨ã—ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
    let lastMousePosition = { x: 0, y: 0 }
    let simulatedFaceCenter = { x: 320, y: 240 } // ç”»é¢ä¸­å¤®
    
    // ãƒžã‚¦ã‚¹ç§»å‹•ã®ç›£è¦–
    document.addEventListener('mousemove', (e) => {
      lastMousePosition = { x: e.clientX, y: e.clientY }
      
      // ãƒžã‚¦ã‚¹ä½ç½®ã‹ã‚‰ã€Œé ­ã®å‘ãã€ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      const screenCenterX = window.innerWidth / 2
      const screenCenterY = window.innerHeight / 2
      
      // ãƒžã‚¦ã‚¹ä½ç½®ã‹ã‚‰é ­éƒ¨å§¿å‹¢ã‚’è¨ˆç®—
      const relativeX = (e.clientX - screenCenterX) / screenCenterX
      const relativeY = (e.clientY - screenCenterY) / screenCenterY
      
      // é¡”ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
      faceDetected.value = true
      faceData.x = simulatedFaceCenter.x
      faceData.y = simulatedFaceCenter.y
      faceData.width = 200
      faceData.height = 200
      faceData.confidence = 0.9
      
      // é ­éƒ¨å§¿å‹¢ã‚’ãƒžã‚¦ã‚¹ä½ç½®ã‹ã‚‰æŽ¨å®š
      faceData.headPose.yaw = relativeX * 30  // -30Â° ~ +30Â°
      faceData.headPose.pitch = relativeY * 20 // -20Â° ~ +20Â°
      faceData.headPose.roll = 0
      
      // çµ±è¨ˆæ›´æ–°
      updateStats()
    })
    
    // ã‚¿ãƒƒãƒãƒ‡ãƒã‚¤ã‚¹å¯¾å¿œ
    document.addEventListener('touchmove', (e) => {
      if (e.touches.length > 0) {
        const touch = e.touches[0]
        const mouseEvent = new MouseEvent('mousemove', {
          clientX: touch.clientX,
          clientY: touch.clientY
        })
        document.dispatchEvent(mouseEvent)
      }
    })
    
    // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æ“ä½œï¼ˆã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ï¼‰
    document.addEventListener('keydown', (e) => {
      const moveStep = 20
      let newX = lastMousePosition.x
      let newY = lastMousePosition.y
      
      switch(e.key) {
        case 'ArrowUp':
          newY = Math.max(0, newY - moveStep)
          break
        case 'ArrowDown':
          newY = Math.min(window.innerHeight, newY + moveStep)
          break
        case 'ArrowLeft':
          newX = Math.max(0, newX - moveStep)
          break
        case 'ArrowRight':
          newX = Math.min(window.innerWidth, newX + moveStep)
          break
        default:
          return
      }
      
      // ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ç§»å‹•ã‚’ãƒžã‚¦ã‚¹ç§»å‹•ã¨ã—ã¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
      const mouseEvent = new MouseEvent('mousemove', {
        clientX: newX,
        clientY: newY
      })
      document.dispatchEvent(mouseEvent)
      e.preventDefault()
    })
    
    // åˆæœŸä½ç½®è¨­å®š
    setTimeout(() => {
      faceDetected.value = true
      faceData.confidence = 0.8
      console.log('âœ… ã‚·ãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ æº–å‚™å®Œäº†')
      console.log('ðŸ’¡ ä½¿ç”¨æ–¹æ³•: ãƒžã‚¦ã‚¹ç§»å‹•ã§è¦–ç·šã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€çŸ¢å°ã‚­ãƒ¼ã§ã‚‚æ“ä½œå¯èƒ½')
    }, 100)
  }
  
  // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  onUnmounted(() => {
    stopTracking()
    if (faceDetection) {
      faceDetection.close()
    }
  })
  
  return {
    // çŠ¶æ…‹
    isInitialized,
    isTracking,
    error,
    faceDetected,
    faceData,
    settings,
    stats,
    
    // ãƒ¡ã‚½ãƒƒãƒ‰
    initializeFaceDetection,
    startTracking,
    stopTracking,
    startCamera
  }
}